{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ef4437",
   "metadata": {},
   "source": [
    "# Model 2: Predicting Bot Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948f47d",
   "metadata": {},
   "source": [
    "The purpose of this model is to predict the performance of the bot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968dc924",
   "metadata": {},
   "source": [
    "## Preliminary Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b6c02",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19864ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f15c9",
   "metadata": {},
   "source": [
    "### Additional Bot Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Data/Model2/model2_data_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40117790",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Bot1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, open_cells = create_grid() # Fixed grid orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09439181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_probabilities(bot, matrix):\n",
    "    directions = {'up': (bot[0], bot[1] - 1), \n",
    "                  'down': (bot[0], bot[1] + 1), \n",
    "                  'left': (bot[0] - 1, bot[1]), \n",
    "                  'right': (bot[0] + 1, bot[1]),\n",
    "                  'stay': bot}\n",
    "    return [matrix.get(directions[direction], 0) for direction in ['up', 'down', 'left', 'right', 'stay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a364980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bot1_collect_data(k, alpha, max_iter, timeout):\n",
    "    global grid, open_cells\n",
    "    \n",
    "    grid, open_cells = reset_grid(grid, open_cells)\n",
    "    bot, ship, open_cells = place_bot(grid, open_cells)\n",
    "\n",
    "    crew_list = []\n",
    "    alien_list = []\n",
    "    d_lookup_table = {}\n",
    "    \n",
    "  #  data_log = [] # Data Log Initialization\n",
    "\n",
    "    crew_list, ship = place_crew(ship, open_cells, crew_list)\n",
    "    alien_list, ship = place_alien(ship, open_cells, alien_list, bot, k)\n",
    "\n",
    "    alien_matrix = initialize_alienmatrix(open_cells, bot, k)\n",
    "    crew_matrix = initialize_crewmatrix(open_cells, crew_list, bot)\n",
    "    \n",
    "    alien_detected = False\n",
    "    crew_detected = False\n",
    "    \n",
    "    next_move_str = 'stay'\n",
    "\n",
    "    win_count = 0\n",
    "    loss_count = 0\n",
    "    move = 0\n",
    "    win_move_count = []\n",
    "    marker = 0\n",
    "    df = pd.DataFrame()\n",
    "    cur_df = pd.DataFrame()\n",
    "    while (win_count + loss_count) < max_iter:\n",
    "        neighbors = check_valid_neighbors(len(ship), bot[0], bot[1])\n",
    "        open_moves = [neigh for neigh in neighbors if (grid[neigh] != 1)]\n",
    "        open_moves.append(bot) # Bot can stay in place \n",
    "        next_move = determine_move(open_moves, alien_matrix, crew_matrix)\n",
    "        \n",
    "#         alien_matrix_str_keys = {str(key): round(value, 5) for key, value in alien_matrix.items()}\n",
    "#         crew_matrix_str_keys = {str(key): round(value, 5) for key, value in crew_matrix.items()}\n",
    "\n",
    "#         alien_matrix_json = json.dumps(alien_matrix_str_keys)\n",
    "#         crew_matrix_json = json.dumps(crew_matrix_str_keys)\n",
    "\n",
    "#         alien_matrix_flat = [round(alien_matrix.get((x, y), 0), 5) for x in range(30) for y in range(30)]\n",
    "#         crew_matrix_flat = [round(crew_matrix.get((x, y), 0), 5) for x in range(30) for y in range(30)]\n",
    "\n",
    "        alien_probs = determine_probabilities(bot, alien_matrix)\n",
    "        crew_probs = determine_probabilities(bot, crew_matrix)\n",
    "        \n",
    "        # Convert relative move to string      \n",
    "        if next_move[0] > bot[0]:\n",
    "            next_move_str = 'right'\n",
    "        elif next_move[0] < bot[0]:\n",
    "            next_move_str = 'left'\n",
    "        elif next_move[1] > bot[1]:\n",
    "            next_move_str = 'up'\n",
    "        elif next_move[1] < bot[1]:\n",
    "            next_move_str = 'down'\n",
    "        else:\n",
    "            next_move_str = 'stay'\n",
    "        \n",
    "        # One-Hot Encoding\n",
    "        actions = {'up': [1, 0, 0, 0, 0], 'down': [0, 1, 0, 0, 0], 'left': [0, 0, 1, 0, 0], 'right': [0, 0, 0, 1, 0], 'stay': [0, 0, 0, 0, 1]}\n",
    "        best_move_encoded = actions[next_move_str]\n",
    "        \n",
    "        log_entry = {\n",
    "            'bot_x': bot[0],\n",
    "            'bot_y': bot[1],\n",
    "            \n",
    "            'alien_up': alien_probs[0],\n",
    "            'alien_down': alien_probs[1],\n",
    "            'alien_left': alien_probs[2],\n",
    "            'alien_right': alien_probs[3],\n",
    "            'alien_stay': alien_probs[4],\n",
    "            \n",
    "            'crew_up': crew_probs[0],\n",
    "            'crew_down': crew_probs[1],\n",
    "            'crew_left': crew_probs[2],\n",
    "            'crew_right': crew_probs[3],\n",
    "            'crew_stay': crew_probs[4],\n",
    "            \n",
    "            'alien_detected': 1 if alien_detected else 0,\n",
    "            'crew_detected': 1 if crew_detected else 0,\n",
    "            \n",
    "            'successful': 0\n",
    "        }\n",
    "       # data_log.append(log_entry)\n",
    "        cur_df = cur_df.append(log_entry, ignore_index=True)\n",
    "        \n",
    "\n",
    "        prev_win_count = win_count\n",
    "        bot, crew_list, ship, open_cells, win_count, marker = move_bot(ship, bot, next_move, crew_list, alien_list, open_cells, win_count, 1)\n",
    "        move += 1\n",
    "\n",
    "        if marker == 1 or move >= timeout:\n",
    "            loss_count += 1\n",
    "            print(f\"Bot captured! Win Count: {win_count}, Loss Count: {loss_count}\")\n",
    "            df = df.append(cur_df, ignore_index=True)\n",
    "            cur_df.drop(cur_df.index, axis=0, inplace=True)\n",
    "            cur_df.drop(cur_df.columns, axis=1, inplace=True)\n",
    "            grid, open_cells = reset_grid(grid, open_cells)\n",
    "            bot, ship, open_cells = place_bot(grid, open_cells)\n",
    "            crew_list = []\n",
    "            alien_list = []\n",
    "            d_lookup_table = {}\n",
    "\n",
    "            crew_list, ship = place_crew(ship, open_cells, crew_list)\n",
    "            alien_list, ship = place_alien(ship, open_cells, alien_list, bot, k)\n",
    "\n",
    "            alien_matrix = initialize_alienmatrix(open_cells, bot, k)\n",
    "            crew_matrix = initialize_crewmatrix(open_cells, crew_list, bot)\n",
    "            marker = 0\n",
    "            move = 0\n",
    "\n",
    "            continue\n",
    "\n",
    "        if win_count > prev_win_count:\n",
    "            print(f\"Crew saved! Win Count: {win_count}, Loss Count: {loss_count}\")\n",
    "            cur_df['successful'] = 1\n",
    "            df = df.append(cur_df, ignore_index=True)\n",
    "            cur_df.drop(cur_df.index, axis=0, inplace=True)\n",
    "            cur_df.drop(cur_df.columns, axis=1, inplace=True)\n",
    "            win_move_count.append(move)\n",
    "            move = 0\n",
    "            d_lookup_table = {}\n",
    "            alien_matrix = initialize_alienmatrix(open_cells, bot, k)\n",
    "            crew_matrix = initialize_crewmatrix(open_cells, crew_list, bot)\n",
    "        \n",
    "       # print(f\"Bot: {bot}, Crew: {crew_list}, Aliens: {alien_list}\")\n",
    "\n",
    "        alien_matrix, crew_matrix = update_afterbotmove(bot, alien_matrix, crew_matrix)\n",
    "\n",
    "        # Move bot to optimal neighbor\n",
    "        marker, alien_list, ship = move_aliens(ship, alien_list, bot) # Move alien randomly\n",
    "\n",
    "        if marker == 1 or move >= timeout:\n",
    "            loss_count += 1\n",
    "            print(f\"Bot captured! Win Count: {win_count}, Loss Count: {loss_count}\")\n",
    "            df = df.append(cur_df, ignore_index=True)\n",
    "            cur_df.drop(cur_df.index, axis=0, inplace=True)\n",
    "            cur_df.drop(cur_df.columns, axis=1, inplace=True)\n",
    "            grid, open_cells = reset_grid(grid, open_cells)\n",
    "            bot, ship, open_cells = place_bot(grid, open_cells)\n",
    "            crew_list = []\n",
    "            alien_list = []\n",
    "            d_lookup_table = {}\n",
    "\n",
    "            crew_list, ship = place_crew(ship, open_cells, crew_list)\n",
    "            alien_list, ship = place_alien(ship, open_cells, alien_list, bot, k)\n",
    "\n",
    "            alien_matrix = initialize_alienmatrix(open_cells, bot, k)\n",
    "            crew_matrix = initialize_crewmatrix(open_cells, crew_list, bot)\n",
    "            marker = 0\n",
    "            move = 0\n",
    "\n",
    "            continue\n",
    "        \n",
    "        alien_matrix = update_afteralienmove(ship, alien_list, alien_matrix) # Update after alien move\n",
    "        \n",
    "        alien_detected = alien_sensor(alien_list, bot, k) # Run Alien Sensor\n",
    "        crew_detected, d_lookup_table = crew_sensor(ship, bot, alpha, d_lookup_table, crew_list) # Run Crew Sensor\n",
    "        \n",
    "        alien_matrix = update_alienmatrix(alien_matrix, alien_detected, bot, k) # Update based on alien sensor\n",
    "\n",
    "        crew_matrix = update_crewmatrix(crew_matrix, crew_detected, d_lookup_table, bot, alpha) # Update based on crew sensor\n",
    "    \n",
    "    df = df.append(cur_df, ignore_index=True)\n",
    "    \n",
    "#     df = pd.DataFrame(data_log)\n",
    "    \n",
    "    if os.path.isfile(file_name):\n",
    "        df.to_csv(file_name, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        df.to_csv(file_name, mode='w', index=False, header=True)\n",
    "\n",
    "    return sum(win_move_count) // max(1, len(win_move_count)), (win_count / max(1, (win_count + loss_count))), win_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b563458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bot1_simulation(alpha_values, k_values, max_iter, timeout, num_simulations):\n",
    "    avg_rescue_moves = {k: [] for k in k_values}\n",
    "    prob_crew_rescue = {k: [] for k in k_values}\n",
    "    avg_crew_saved = {k: [] for k in k_values}\n",
    "\n",
    "    for k in k_values:\n",
    "        for alpha in alpha_values:\n",
    "            total_metric1, total_metric2, total_metric3 = 0, 0, 0\n",
    "            \n",
    "            for i in range(num_simulations):\n",
    "                metric1, metric2, metric3 = Bot1_collect_data(k, alpha, max_iter, timeout)\n",
    "                total_metric1 += metric1\n",
    "                total_metric2 += metric2\n",
    "                total_metric3 += metric3\n",
    "\n",
    "            avg_metric1 = total_metric1 / num_simulations\n",
    "            avg_metric2 = total_metric2 / num_simulations\n",
    "            avg_metric3 = total_metric3 / num_simulations\n",
    "\n",
    "            print(f\"k: {k}, Alpha: {alpha}\\nAverage Rescue Moves: {avg_metric1}\\nProbability of Crew Rescue: {avg_metric2}\\nAverage Crew Saved: {avg_metric3}\\n\")\n",
    "\n",
    "            avg_rescue_moves[k].append(avg_metric1)\n",
    "            prob_crew_rescue[k].append(avg_metric2)\n",
    "            avg_crew_saved[k].append(avg_metric3)\n",
    "\n",
    "    return avg_rescue_moves, prob_crew_rescue, avg_crew_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_alien_one_crew(alpha_values, k_values, max_iter, timeout, num_simulations):\n",
    "    bot1_avg_rescue_moves, bot1_prob_crew_rescue, bot1_avg_crew_saved = Bot1_simulation(alpha_values, k_values, max_iter, timeout, num_simulations)\n",
    "\n",
    "    bot1_prob_crew_rescue = {k: [round(prob, 3) for prob in probs] for k, probs in bot1_prob_crew_rescue.items()}\n",
    "\n",
    "    print(bot1_avg_rescue_moves, bot1_prob_crew_rescue, bot1_avg_crew_saved, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0.004] # 0.004 > 0.01\n",
    "k_values = [3]\n",
    "max_iter = 30\n",
    "timeout = 10000\n",
    "num_simulations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1db10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_alien_one_crew(alpha_values, k_values, max_iter, timeout, num_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k: 3, Alpha: 0.004\n",
    "# Average Rescue Moves: 585.05\n",
    "# Probability of Crew Rescue: 0.71\n",
    "# Average Crew Saved: 21.3\n",
    "\n",
    "# {3: [585.05]} {3: [0.71]} {3: [21.3]} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d030cf",
   "metadata": {},
   "source": [
    "### Model 1 Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Function\n",
    "def softmax(z):\n",
    "    e_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return e_z / np.sum(e_z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0009e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7705994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and biases\n",
    "def init_params(num_features, num_classes):\n",
    "    W = np.random.randn(num_features, num_classes) * 0.01 # Initialize to a small random number\n",
    "    b = np.zeros((1, num_classes))\n",
    "#     print(W, b, W.shape, b.shape)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ce4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def loss_function(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    #return -np.sum(np.full((m, 2), [1.556, 0.737])*y_true * np.log(y_pred + 1e-15)) / m # Class weights due to imbalance in data\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-15)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "def compute_gradient(X, y_true, y_pred):\n",
    "    m = X.shape[0]\n",
    "    der_z = y_pred - y_true\n",
    "    # dW = 1/m * np.dot(X.T, der_z * np.full((m, 2), [1.556, 0.737])) # Class weights due to imbalance in data\n",
    "    #db = 1/m * np.sum(der_z * np.full((m, 2), [1.556, 0.737]), axis=0, keepdims=True)\n",
    "    dW = 1/m * np.dot(X.T, der_z)\n",
    "    db = 1/m * np.sum(der_z, axis=0, keepdims=True)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d242fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function\n",
    "def predict(X, W, b):\n",
    "\n",
    "    z = np.dot(X, W) + b\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91371d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function to account for cases with invalid predictions\n",
    "# For example, [0, 0.1, 0.2, 0.4, 0.3] would become [0, 0.1, 0, 0, 0.3] if left and right were invalid, and then normalization would cause it to become [0, 0.25, 0, 0, 0.75]\n",
    "def predict_constrained(X, W, b, valid):\n",
    "    y_pred = predict(X, W, b)\n",
    "    \n",
    "    valid_y_pred = y_pred * valid\n",
    "    valid_y_pred_sum = valid_y_pred.sum(axis=1, keepdims=True)\n",
    "    valid_y_pred /= valid_y_pred_sum\n",
    "    \n",
    "    one_hot_pred = np.zeros_like(valid_y_pred, dtype=int)\n",
    "    one_hot_pred[np.arange(len(valid_y_pred)), np.argmax(valid_y_pred, axis=1)] = 1\n",
    "\n",
    "    return one_hot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function that uses SGD and GD\n",
    "def train(X, y, alpha, epochs, initial_batch_size, loss_threshold):\n",
    "    num_features = X.shape[1]\n",
    "    num_classes = 2\n",
    "    n = X.shape[0]\n",
    "\n",
    "    W, b = init_params(num_features, num_classes)\n",
    "#     print(W, b)\n",
    "\n",
    "    previous_loss = float('inf')  # Set starting loss to infinity\n",
    "    batch_size = n  # Start with SGD (smaller batch size)\n",
    "    switched_to_gd = False\n",
    "    loss_list = []  # Store loss values over time\n",
    "    \n",
    "    # Number of times iterated through entire dataset\n",
    "    for epoch in range(epochs):\n",
    "        current_loss = 0\n",
    "        \n",
    "        # Only iterate over batch size. In SGD, batch size is small, so iterate over smaller batches and update loss\n",
    "        for i in range(0, n, batch_size):\n",
    "            X_batch = X.iloc[i:i + batch_size]\n",
    "            y_batch = y.iloc[i:i + batch_size]\n",
    "            replace_exp = lambda x: np.eye(2)[0] if x == 0 else np.eye(2)[1]\n",
    "            y_batch['successful'] = y_batch['successful'].apply(replace_exp)\n",
    "            y_pred = predict(X_batch, W, b)\n",
    "            \n",
    "# # #             print(y_batch, y_pred, valid_batch)\n",
    "            batch_loss = loss_function(np.vstack(y_batch['successful'].values), y_pred)\n",
    "\n",
    "            current_loss += batch_loss\n",
    "\n",
    "            dW, db = compute_gradient(X_batch, np.vstack(y_batch['successful'].values), y_pred)\n",
    "            W -= alpha * dW\n",
    "            b -= alpha * db\n",
    "\n",
    "        current_loss /= (n // batch_size)\n",
    "        loss_list.append(current_loss)\n",
    "\n",
    "# #         # Check if loss threshold is met to switch to GD\n",
    "#         if not switched_to_gd and abs(previous_loss - current_loss) < loss_threshold:\n",
    "#             batch_size = n  # Set batch size to full dataset (switch to Gradient Descent)\n",
    "#             switched_to_gd = True\n",
    "#             print(f\"Switched to Gradient Descent. Epoch: {epoch}\")\n",
    "\n",
    "        previous_loss = current_loss\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {current_loss}\")\n",
    "\n",
    "      \n",
    "    return W, b, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(x, y, move, grid, open_cells):\n",
    "    if move == 'up' and (x, y + 1) in open_cells:\n",
    "        return 1\n",
    "    elif move == 'down' and (x, y - 1) in open_cells:\n",
    "        return 1\n",
    "    elif move == 'left' and (x - 1, y) in open_cells:\n",
    "        return 1\n",
    "    elif move == 'right' and (x + 1, y) in open_cells:\n",
    "        return 1\n",
    "    elif move == 'stay':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679450e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, open_cells = reset_grid(grid, open_cells)\n",
    "\n",
    "def create_valid_matrix(X):\n",
    "    global grid, open_cells\n",
    "    directions = ['up', 'down', 'left', 'right', 'stay']\n",
    "    valid_list = []\n",
    "    for i in range(len(X)):\n",
    "        x, y = X.iloc[i, 0], X.iloc[i, 1]\n",
    "        validity_for_each_direction = [is_valid(x, y, move, grid, open_cells) for move in directions]\n",
    "        valid_list.append(validity_for_each_direction)\n",
    "\n",
    "    valid_array = np.array(valid_list)\n",
    "    return valid_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(loss_list):\n",
    "    directory = \"Results/Model2\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    filename = f\"loss_plot_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_list, label='Loss per Epoch')\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.savefig(filepath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997651bc",
   "metadata": {},
   "source": [
    "### Model 1 Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = (y_true == y_pred)\n",
    "    accuracy = correct_predictions.sum() / correct_predictions.size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(W, b, X_train, y_train,X_test, y_test):\n",
    "    y_batch_train = y_train.iloc[0:]\n",
    "    y_batch_test = y_test.iloc[0:]\n",
    "    replace_exp = lambda x: np.eye(2)[0] if x == 0 else np.eye(2)[1]\n",
    "    y_batch_train['successful'] = y_batch_train['successful'].apply(replace_exp)\n",
    "    y_batch_test['successful'] = y_batch_test['successful'].apply(replace_exp)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     y_train_true = np.array(y_train_df.apply(ast.literal_eval).tolist())\n",
    "#     y_test_true = np.array(y_test_df.apply(ast.literal_eval).tolist())\n",
    "    \n",
    "    y_train_pred = predict(X_train, W, b)\n",
    "    y_train_pred_binary = (y_train_pred >= 0.5).astype(int)\n",
    "    \n",
    "\n",
    "# #     print(y_train_true, y_train_pred)\n",
    "    train_acc = calculate_accuracy(np.vstack(y_batch_train['successful'].values), y_train_pred_binary)\n",
    "    y_test_pred = predict(X_test, W, b)\n",
    "    y_test_pred_binary = (y_test_pred >= 0.5).astype(int)\n",
    "    \n",
    "#     y_test_pred = predict(X_test, W, b)\n",
    "    test_acc = calculate_accuracy(np.vstack(y_batch_test['successful'].values), y_test_pred_binary)\n",
    "    \n",
    "    print(f\"Training Accuracy: {train_acc}\\nTesting Accuracy: {test_acc}\")\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c85fa",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49718ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Model2/model2_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21688d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e85228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a020ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df = data.drop_duplicates()\n",
    "model2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf73ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df[model2_df['successful'] == 0.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2247946",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97866f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_training = 0.80\n",
    "percentage_test = 0.20\n",
    "\n",
    "\n",
    "\n",
    "num_rows_total = model2_df.shape[0]\n",
    "num_rows_training = int(percentage_training * num_rows_total)\n",
    "num_rows_test = int(percentage_test * num_rows_total)\n",
    "\n",
    "shuffled_indices = np.random.permutation(num_rows_total)\n",
    "\n",
    "\n",
    "# Split the indices into training and test sets\n",
    "training_indices = shuffled_indices[:num_rows_training]\n",
    "test_indices = shuffled_indices[num_rows_training:num_rows_training + num_rows_test]\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(model2_df))\n",
    "\n",
    "train_df = model2_df.iloc[training_indices, :]\n",
    "test_df = model2_df.iloc[test_indices, :]\n",
    "\n",
    "#Make sure equal number of points from both classes in training matrix \n",
    "# num_rows_total = model2_df.shape[0]\n",
    "# shuffled_indices = np.random.permutation(num_rows_total)\n",
    "# x = model2_df[model2_df['successful'] == 1.0]\n",
    "# filtered_1 = np.random.choice(x.shape[0], model2_df[model2_df['successful'] == 0.0].shape[0], replace=False)\n",
    "# train_df = pd.concat([model2_df[model2_df['successful'] == 0.0], x.iloc[filtered_1, :]])\n",
    "# percentage_test = 0.20\n",
    "# num_rows_test = int(percentage_test * num_rows_total)\n",
    "# test_indices = shuffled_indices[num_rows_training:num_rows_training + num_rows_test]\n",
    "# test_df = model2_df.iloc[test_indices, :]\n",
    "\n",
    "#########\n",
    "\n",
    "# # Choose the percentage for training and test sets\n",
    "# percentage_training = 0.80\n",
    "# percentage_test = 0.20\n",
    "\n",
    "# # Calculate the number of rows for training and test sets\n",
    "# num_rows_total = model2_df.shape[0]\n",
    "# num_rows_training = int(percentage_training * num_rows_total)\n",
    "# num_rows_test = int(percentage_test * num_rows_total)\n",
    "\n",
    "# shuffled_indices = np.random.permutation(num_rows_total)\n",
    "\n",
    "\n",
    "# # Split the indices into training and test sets\n",
    "# training_indices = shuffled_indices[:num_rows_training]\n",
    "# test_indices = shuffled_indices[num_rows_training:num_rows_training + num_rows_test]\n",
    "\n",
    "\n",
    "# # # Create the training set\n",
    "# training_set = model2_df.iloc[training_indices, :]\n",
    "\n",
    "# # Define output column \n",
    "# wanted_column = -1\n",
    "\n",
    "# # Filter the dataset to get rows with value 1 \n",
    "# filteredvalue_1 = training_set.loc[training_set.iloc[:, wanted_column] == 1]\n",
    "\n",
    "# # Filter the dataset to get rows with value 0 \n",
    "# filteredvalue_0 = training_set.loc[training_set.iloc[:, wanted__column] == 0]\n",
    "\n",
    "# # Calculate the number of samples needed for training \n",
    "# num_samples = num_rows_training // 2\n",
    "\n",
    "# # Randomly select 50% of the rows with value 1 \n",
    "# training_value_1 = np.random.choice(filteredvalue_1.shape[0], num_samples, replace=False)\n",
    "# training_dataset_1 = filteredvalue_1.iloc[training_value_1, :]\n",
    "\n",
    "# # Randomly select 50% of the rows with value 0 \n",
    "# training_value_0 = np.random.choice(filteredvalue_0.shape[0], num_samples)\n",
    "# training_dataset_0 = filtered_rows_value_0.iloc[training_value_0, :]\n",
    "\n",
    "# # # Combine datasets to create final training data set\n",
    "# train_df = pd.concat([training_dataset_1, training_dataset_0])\n",
    "\n",
    "# # Create the test set\n",
    "# test_df = model2_df.iloc[test_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24978a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38998271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv('Data/Model2/model2_train.csv', index=False)\n",
    "#test_df.to_csv('Data/Model2/model2_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b91bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,:-1]\n",
    "y_train = train_df.iloc[:,-1:]\n",
    "\n",
    "X_test = test_df.iloc[:,:-1]\n",
    "y_test = test_df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179316b0",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0963633",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "epochs = 50\n",
    "initial_batch_size = 32\n",
    "loss_threshold = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a52251",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b, loss_list = train(X_train, y_train, alpha, epochs, initial_batch_size, loss_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fd25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdea11f",
   "metadata": {},
   "source": [
    "## Model Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15063b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(W, b, X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_random_acc = 1\n",
    "max_random_acc = 0\n",
    "\n",
    "for i in range(100):\n",
    "    random_W = np.random.randn(14, 2) * 0.01\n",
    "    random_b = np.zeros((1, 2))\n",
    "    \n",
    "    _, random_test_acc = test(random_W, random_b, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    max_random_acc = max(max_random_acc, random_test_acc)\n",
    "    min_random_acc = min(min_random_acc, random_test_acc)\n",
    "\n",
    "print(f\"Random W, b accuracy in range: ({min_random_acc}, {max_random_acc})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
